{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import enum\n",
    "import itertools\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@enum.unique\n",
    "class Grade(enum.IntEnum):\n",
    "    \"\"\"\n",
    "    Represents relevance on a graded scale. \n",
    "    Any positive number represents relevance, with higher numbers representing higher relevance (total ordering)\n",
    "    Zero represents irrelevant\n",
    "    \"\"\"\n",
    "    N = (0)   # Not relevant\n",
    "    R = (1)   # Relevant\n",
    "    HR = (2)  # Highly relevant\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def is_relevant(self):\n",
    "        \"\"\"\n",
    "        'Binarizes' the relevance. Useful for computing binary metrics like precision / recall\n",
    "        \"\"\"\n",
    "        return False if self.value == 0 else True\n",
    "    \n",
    "    @classmethod\n",
    "    def from_int_list(cls, int_list):\n",
    "        \"\"\"\n",
    "        Converts a list of integers to a list of Grade\n",
    "        \"\"\"\n",
    "        members = dict((member.value, member) for member in cls.__members__.values())\n",
    "        return [members[value] for value in int_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_permutations(grade, sequence_length):\n",
    "    \"\"\"\n",
    "    For a given grade and a sequence length n, returns all possible permutations of length n that can be formed. \n",
    "    Note that a generator is returned and not a list\n",
    "    \"\"\"\n",
    "    for i, perm in enumerate(itertools.product(range(len(grade.__members__)), repeat=sequence_length)):\n",
    "        yield grade.from_int_list(perm)\n",
    "\n",
    "def get_all_permutation_pairs(grade, sequence_length):\n",
    "    \"\"\"\n",
    "    Generates all possible pairs of permutations given a grade and a sequence length.\n",
    "    Note that a generator is returned and not a list\n",
    "    \"\"\"\n",
    "    sequence_1 = get_all_permutations(grade, sequence_length)\n",
    "    sequence_2 = get_all_permutations(grade, sequence_length)    \n",
    "    for pair in itertools.product(sequence_1, sequence_2):\n",
    "        p1, p2 = pair\n",
    "        # don't return exact duplicates\n",
    "        if all(map(lambda _ : _[0] == _[1], zip(p1, p2))) == True:\n",
    "            continue\n",
    "        yield pair\n",
    "\n",
    "def count_sequence(seq):\n",
    "    \"\"\"\n",
    "    `len` for generators\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for _ in seq:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "# A sanity check to ensure the correct number of sequences are being generated\n",
    "# the `-(3**5)` removes exact duplicates\n",
    "assert count_sequence(get_all_permutation_pairs(Grade, 5)) == (3**5) * (3**5) - (3 ** 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Simulate Rankings of Relevance for E and P (5 points)\n",
    "\n",
    "In the first step you will generate pairs of rankings of relevance, for the production P and experimental E, respectively, for a hypothetical query q. Assume a 3-graded relevance, i.e. {N, R, HR}. Construct all possible P and E ranking pairs of length 5. This step should give you about.\n",
    "\n",
    "Example:\n",
    "\n",
    "P: {N N N N N}\n",
    "E: {N N N N R}\n",
    "\n",
    "‚Ä¶\n",
    "P: {HR HR HR HR R}\n",
    "E: {HR HR HR HR HR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutations = list(get_all_permutation_pairs(Grade, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<Grade.N: 0>, <Grade.N: 0>, <Grade.N: 0>, <Grade.N: 0>, <Grade.N: 0>],\n",
       " [<Grade.N: 0>, <Grade.N: 0>, <Grade.N: 0>, <Grade.N: 0>, <Grade.R: 1>])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<Grade.HR: 2>, <Grade.HR: 2>, <Grade.HR: 2>, <Grade.HR: 2>, <Grade.HR: 2>],\n",
       " [<Grade.HR: 2>, <Grade.HR: 2>, <Grade.HR: 2>, <Grade.HR: 2>, <Grade.R: 1>])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutations[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Implement Evaluation Measures (10 points)\n",
    "Implement 1 binary and 2 multi-graded evaluation measures out of the 7 measures mentioned above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric:\n",
    "    def compute(production, experimental, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "class ContigencyTable(Metric):\n",
    "    def __init__(self):\n",
    "        self.true_positive = None\n",
    "        self.true_negative = None\n",
    "        self.false_negative = None\n",
    "        self.false_positive = None\n",
    "    \n",
    "    def compute(production, experimental):\n",
    "        for p, e in zip(production, experimental):\n",
    "            # binarize\n",
    "            p, e = p.is_relevant, e.is_relevant\n",
    "            if p == True and e == True:\n",
    "                self.true_positive += 1\n",
    "            elif p == True and e == False:\n",
    "                self.false_negative += 1\n",
    "            elif p == False and e == True:\n",
    "                self.false_positive += 1\n",
    "            else:\n",
    "                self.false_negative += 1    \n",
    "        \n",
    "        \n",
    "class Precision(Metric):\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return \"precision\"\n",
    "    \n",
    "    def compute(production, experimental, **kwargs):\n",
    "        if k not in kwargs:\n",
    "            raise ValueError(\"Precision requires parameter 'k'\")\n",
    "\n",
    "class Recall(Metric):\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return \"recall\"\n",
    "    \n",
    "    \n",
    "    def compute(production, experimental, **kwargs):\n",
    "        if k not in kwargs:\n",
    "            raise ValueError(\"Recall requires parameter 'k'\")\n",
    "\n",
    "class AveragePrecision(Metric):\n",
    "    def compute(production, experimental, **kwargs):\n",
    "        if k not in kwargs:\n",
    "            raise ValueError(\"Recall requires parameter 'k'\")\n",
    "\n",
    "\n",
    "class GradedMetric:\n",
    "    def compute(production, experimental, grade, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "class NDCG(GradedMetric):\n",
    "    pass\n",
    "\n",
    "class ERR(GradedMetric):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Calculate the ùõ•measure (0 points)\n",
    "\n",
    "For the three measures and all P and E ranking pairs constructed above calculate the difference: ùõ•measure = measureE-measureP. Consider only those pairs for which E outperforms P."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_measures_binary = {\n",
    "    \"precision\": np.zeros(len(permutations)),\n",
    "    \"recall\": np.zeros(len(permutations)),\n",
    "}\n",
    "\n",
    "del_measures_graded = {\n",
    "    \"EER\": np.zeros(len(permutations)),\n",
    "    \"NDCG\": np.zeros(len(permutations))\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
